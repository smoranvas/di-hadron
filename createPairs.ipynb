{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyternotify extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyternotify\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "from ROOT import TFile\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pandas as pd \n",
    "import time\n",
    "from os import listdir\n",
    "import uproot3\n",
    "import uproot\n",
    "import root_pandas\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class particle:\n",
    "    def __init__(self, pid, fourvector, virtual_photon,ThetaPQ ):## '__init__' is the constructor of the class\n",
    "        self.virtual_photon = virtual_photon\n",
    "        Nu = virtual_photon.E()   ##components of a 4-vector TLorentzVector\n",
    "        Q2 = -virtual_photon.M2() ## magnitud squared of a 4-vector TLorentzVector\n",
    "        self.proton = ROOT.TLorentzVector()  ## proton is an attribute of the class 'particle' just created.\n",
    "        self.proton.SetPxPyPzE(0,0,0, 0.938)  ## SetPxPyPzE is just a function of ROOT\n",
    "        self.W = (virtual_photon + self.proton).M() ##.M() return the magnitud of a TLorentzVector [W2=(p+q)2]\n",
    "        incoming_e = ROOT.TLorentzVector()\n",
    "        incoming_e.SetPxPyPzE(0,0,5.014,5.014)\n",
    "        part1 = virtual_photon.Vect().Cross(incoming_e.Vect()).Unit()\n",
    "        part2 = virtual_photon.Vect().Cross(fourvector.Vect()).Unit()\n",
    "        sign  = np.sign(part1.Dot(fourvector.Vect())) ## sign returns -1 0 or 1 if the input is negative, zero or positive.\n",
    "        self.PhiPQ = sign*np.arccos(part1.Dot(part2))\n",
    "        photon_pz = np.sqrt(Nu*Nu+Q2) #direction is positive by definition, virtual photon\n",
    "        self.bcm = photon_pz/(Nu + 0.938)#photon-nucleon center-of-mass velocity \n",
    "        self.ycm = 0.5*np.log(( 1+self.bcm)/(1-self.bcm)) #photon-nucleon center-of-mass rapidity\n",
    "        self.LorentzVector = fourvector #hadron four-vector. 4-vector is an input of this class\n",
    "        self.PhiLab = self.LorentzVector.Phi()\n",
    "        self.ThetaLab = self.LorentzVector.Theta()\n",
    "        self.E = self.LorentzVector.E() #energy in lab frame\n",
    "        self.vector = self.LorentzVector.Vect()\n",
    "        self.Pt = self.vector.Perp(virtual_photon.Vect().Unit()) #pT with respect to photon direction\n",
    "        self.Pl  = self.vector.Dot(virtual_photon.Vect().Unit()) #pL with respect to photon direction (in lab frame)\n",
    "        self.y =  0.5*np.log( (self.E+self.Pl)/(self.E-self.Pl)) #rapidity in lab frame\n",
    "        self.mT = np.sqrt(self.LorentzVector.M2() + self.Pt*self.Pt)\n",
    "        self.y_star = self.y - self.ycm\n",
    "        self.Pl_star = self.mT*np.sinh(self.y_star) # y is rapidity\n",
    "        self.Xf = 2.0*self.Pl_star/self.W \n",
    "        self.pid = pid\n",
    "        self.Zh = self.E/Nu\n",
    "        self.ThetaPQ = np.arctan(self.Pt/self.Pl)\n",
    "        self.P = np.sqrt(self.LorentzVector.Px()**2+self.LorentzVector.Py()**2+self.LorentzVector.Pz()**2)\n",
    "      \n",
    "    def redefine(self, new_virtual_photon):\n",
    "        incoming_e = ROOT.TLorentzVector()\n",
    "        incoming_e.SetPxPyPzE(0,0,5.014,5.014)\n",
    "        part1 = new_virtual_photon.Vect().Cross(incoming_e.Vect()).Unit()\n",
    "        part2 = new_virtual_photon.Vect().Cross(self.LorentzVector.Vect()).Unit()\n",
    "        sign  = np.sign(part1.Dot(self.LorentzVector.Vect()))\n",
    "        self.PhiPQ = sign*np.arccos(part1.Dot(part2)) \n",
    "        self.Pt = self.LorentzVector.Vect().Perp(new_virtual_photon.Vect().Unit()) #pT with respect to photon direction\n",
    "        self.Pl  = self.LorentzVector.Vect().Dot(new_virtual_photon.Vect().Unit()) #pL with respect to photon direction (in lab frame)\n",
    "        self.y =  0.5*np.log( (self.E+self.Pl)/(self.E-self.Pl)) #rapidity in lab frame\n",
    "        self.ThetaPQ = np.arctan(self.Pt/self.Pl)\n",
    "        self.virtual_photon = new_virtual_photon\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def print_properties(self):\n",
    "        print ('Hello, let me introduce myself, i am particle pid = ' , self.pid, ' with index ', self.index, ', from event  #', self.ievt, ' Nu and W', self.Nu, ' ' , self.W)\n",
    "        print ('zh = ', self.Zh, ' phi_pq= ', self.PhiPQ, ' theta_pq=' , self.ThetaPQ, 'E = ', self.E, ' xf', self.Xf,'Pt ', self.Pt, ' Pl= ', self.Pl, ' rapidity=' ,  self.y)\n",
    "        print ('pid = ' , self.pid)       \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def getDataframes(filename, Target=1,maxevents=1e9,tree_name='ntuple_data',isMC=False,keepH2FailRecon=False, h2CutsTruth=False):\n",
    "    dphi = np.array([])  \n",
    "    include_truth=isMC\n",
    "    ParticlesFromPrevious = []\n",
    "    \n",
    "    try:\n",
    "        myfile = TFile.Open('%s'%filename,'READ')\n",
    "        myfile.Print()\n",
    "    except:\n",
    "        print(\"could not open file\")\n",
    "    mytree = myfile.Get(tree_name)\n",
    "        \n",
    "    print (filename, ' has ', mytree.GetEntries(), ' entries')\n",
    "    \n",
    "    tupla = {}  \n",
    "    tupla['dphi'] = [] \n",
    "    tupla['dphi_lab'] = []\n",
    "    tupla['drap'] = []\n",
    "    tupla['h1_z'] = [] \n",
    "    tupla['h2_z'] = []\n",
    "    tupla['h1_cm_pt'] = []\n",
    "    tupla['h2_cm_pt'] = []\n",
    "    tupla['h1_xf'] = []\n",
    "    tupla['h2_xf'] = []\n",
    "    tupla['h1_rap'] = []\n",
    "    tupla['ycm'] = []\n",
    "    tupla['h2_rap'] = []\n",
    "    tupla['h1_pid'] = []\n",
    "    tupla['h2_pid'] = []\n",
    "    tupla['h1_cm_ph'] = []\n",
    "    tupla['h2_cm_ph'] = []\n",
    "    tupla['h1_cm_th'] = []  \n",
    "    tupla['h2_cm_th'] = []  \n",
    "    tupla['pair_mass'] = []\n",
    "    tupla['pair_pt'] = []\n",
    "    tupla['mx_eh1h2x'] = []\n",
    "    tupla['mx_eh1x'] = []\n",
    "    tupla['mx_eh2x'] = []\n",
    "    tupla['t']  = []\n",
    "    tupla['Q2'] = [] \n",
    "    tupla['nu'] = []\n",
    "    tupla['W']  = []\n",
    "    tupla['e_px'] = [] \n",
    "    tupla['e_py'] = []\n",
    "    tupla['e_pz']  = []\n",
    "    tupla['e_p'] = [] \n",
    "    tupla['e_ph'] = []\n",
    "    tupla['e_th']  = []\n",
    "    tupla['SampFracEl25'] = []\n",
    "    tupla['SampFracEl20'] = []\n",
    "    tupla['TargTypeSM'] = [] ## RD's vertex cuts\n",
    "    tupla['TargType'] = []   ## Taisiya's vertex cuts (nominal)\n",
    "    tupla['x'] = [] ## bjorken x\n",
    "    tupla['u']  = []\n",
    "    tupla['h1_ph'] = []\n",
    "    tupla['h1_th'] = []\n",
    "    tupla['h2_ph'] = []\n",
    "    tupla['h2_th'] = []\n",
    "    tupla['h1_deltaZ'] = []\n",
    "    tupla['h2_deltaZ'] = []\n",
    "    tupla['h1_Nphe'] = []\n",
    "    tupla['h2_Nphe'] = []\n",
    "    tupla['h1_Sector'] = []\n",
    "    tupla['h2_Sector'] = []\n",
    "    tupla['h1_FidCut'] = []\n",
    "    tupla['h2_FidCut'] = []\n",
    "    tupla['h1_FidCutPiPlus'] = []\n",
    "    tupla['h2_FidCutPiPlus'] = []\n",
    "    tupla['h1_Chi2CC'] = []\n",
    "    tupla['h2_Chi2CC'] = []\n",
    "    tupla['h1_StatCC'] = []\n",
    "    tupla['h2_StatCC'] = []\n",
    "    tupla['h1_Betta'] = []\n",
    "    tupla['h2_Betta'] = []\n",
    "    tupla['h1_T4'] = []\n",
    "    tupla['h2_T4'] = []    \n",
    "    tupla['evnt']  = []\n",
    "    if keepH2FailRecon:\n",
    "        tupla['pass_recon'] = []\n",
    "    if not isMC:\n",
    "        tupla['run'] = []\n",
    "\n",
    "    #mc truth variables (added by Sebouh)\n",
    "    if include_truth:\n",
    "        tupla['dphi_truth'] = [] \n",
    "        tupla['dphi_lab_truth'] = []\n",
    "        tupla['drap_truth'] = []\n",
    "        tupla['h1_truth_z'] = [] \n",
    "        tupla['h2_truth_z'] = []\n",
    "        tupla['h1_truth_cm_pt'] = []\n",
    "        tupla['h2_truth_cm_pt'] = []\n",
    "        tupla['h1_truth_xf'] = []\n",
    "        tupla['h2_truth_xf'] = []\n",
    "        tupla['h1_truth_rap'] = []\n",
    "        tupla['ycm_truth'] = []\n",
    "        tupla['h2_truth_rap'] = []\n",
    "        tupla['h1_truth_pid'] = []\n",
    "        tupla['h2_truth_pid'] = []\n",
    "        tupla['h1_truth_cm_ph'] = []\n",
    "        tupla['h2_truth_cm_ph'] = []\n",
    "        tupla['h1_truth_cm_th'] = []  \n",
    "        tupla['h2_truth_cm_th'] = []  \n",
    "        tupla['pair_mass_truth'] = []\n",
    "        tupla['pair_pt_truth'] = []\n",
    "        tupla['mx_eh1h2x_truth'] = []\n",
    "        tupla['mx_eh1x_truth'] = []\n",
    "        tupla['mx_eh2x_truth'] = []\n",
    "        tupla['t_truth']  = []\n",
    "        tupla['Q2_truth'] = [] \n",
    "        tupla['nu_truth'] = []\n",
    "        tupla['W_truth']  = []\n",
    "        tupla['x_truth'] = []\n",
    "        tupla['u_truth']  = []\n",
    "        tupla['h1_truth_ph'] = []\n",
    "        tupla['h1_truth_th'] = []\n",
    "        tupla['h2_truth_ph'] = []\n",
    "        tupla['h2_truth_th'] = []\n",
    "        tupla['e_truth_px'] = [] \n",
    "        tupla['e_truth_py'] = []\n",
    "        tupla['e_truth_pz']  = []\n",
    "        tupla['e_truth_p'] = [] \n",
    "        tupla['e_truth_ph'] = []\n",
    "        tupla['e_truth_th']  = []    \n",
    "    \n",
    "    ## here we create another dictionary\n",
    "    tupla_mix = {}\n",
    "    tupla_mix['dphi'] = []\n",
    "    tupla_mix['dphi_lab'] = []\n",
    "    tupla_mix['drap'] = []\n",
    "    tupla_mix['h1_z'] = []\n",
    "    tupla_mix['h2_z'] = []\n",
    "    tupla_mix['h1_cm_pt'] = []\n",
    "    tupla_mix['h2_cm_pt'] = []\n",
    "    tupla_mix['h1_xf'] = []\n",
    "    tupla_mix['h2_xf'] = []\n",
    "    tupla_mix['h1_rap'] = []\n",
    "    tupla_mix['ycm'] = []\n",
    "    tupla_mix['h2_rap'] = []\n",
    "    tupla_mix['h1_pid'] = []\n",
    "    tupla_mix['h2_pid'] = []\n",
    "    tupla_mix['h1_cm_ph']   = []\n",
    "    tupla_mix['h2_cm_ph'] = []\n",
    "    tupla_mix['h1_cm_th'] = []\n",
    "    tupla_mix['h2_cm_th'] = []\n",
    "    tupla_mix['pair_mass'] = []\n",
    "    tupla_mix['pair_pt'] = []\n",
    "    tupla_mix['mx_eh1h2x'] = []\n",
    "    tupla_mix['mx_eh1x'] = []\n",
    "    tupla_mix['mx_eh2x'] = []\n",
    "    tupla_mix['t']  = []\n",
    "    tupla_mix['Q2'] = []\n",
    "    tupla_mix['nu'] = []\n",
    "    tupla_mix['W']  = []\n",
    "    tupla_mix['SampFracEl25'] = []\n",
    "    tupla_mix['SampFracEl20'] = []\n",
    "    tupla_mix['TargTypeSM'] = [] ## RD's vertex cuts\n",
    "    tupla_mix['TargType'] = []   ## Taisiya's vertex cuts (nominal)\n",
    "    tupla_mix['x'] = []\n",
    "    tupla_mix['u']  = []\n",
    "    tupla_mix['h1_ph'] = []\n",
    "    tupla_mix['h1_th'] = []\n",
    "    tupla_mix['h2_ph'] = []\n",
    "    tupla_mix['h2_th'] = []\n",
    "    tupla_mix['dphi_norot'] = [] #save variable before rotation to new virtual photon frame\n",
    "    tupla_mix['h2_cm_ph_norot'] = [] #save variable before rotation to new virtual photon frame\n",
    "    tupla_mix['h2_cm_th_norot'] = [] #save variable before rotation to new virtual photon frame\n",
    "    tupla_mix['h1_deltaZ'] = []\n",
    "    tupla_mix['h2_deltaZ'] = []\n",
    "    tupla_mix['h1_Nphe'] = []\n",
    "    tupla_mix['h2_Nphe'] = []\n",
    "    tupla_mix['h1_Sector'] = []\n",
    "    tupla_mix['h2_Sector'] = []\n",
    "    tupla_mix['h1_FidCut'] = []\n",
    "    tupla_mix['h2_FidCut'] = []    \n",
    "    tupla_mix['h1_FidCutPiPlus'] = []\n",
    "    tupla_mix['h2_FidCutPiPlus'] = []       \n",
    "    tupla_mix['h1_Chi2CC'] = []\n",
    "    tupla_mix['h2_Chi2CC'] = []\n",
    "    tupla_mix['h1_StatCC'] = []\n",
    "    tupla_mix['h2_StatCC'] = []\n",
    "    tupla_mix['evnt'] = []\n",
    "    if not isMC:\n",
    "        tupla_mix['run'] = []\n",
    "    \n",
    "    ## here we create another dictionary\n",
    "    tupla_trigger = {}\n",
    "    tupla_trigger['h1_pid'] = []\n",
    "    tupla_trigger['h1_xf'] = []\n",
    "    tupla_trigger['h1_xf_default'] = []\n",
    "    tupla_trigger['h1_z']  = []\n",
    "    tupla_trigger['h1_cm_pt'] = []\n",
    "    tupla_trigger['h1_rap']  = []\n",
    "    tupla_trigger['ycm'] = []\n",
    "    tupla_trigger['Q2'] = []\n",
    "    tupla_trigger['x'] = []\n",
    "    tupla_trigger['nu'] = []\n",
    "    tupla_trigger['W'] = []\n",
    "    tupla_trigger['e_px'] = [] \n",
    "    tupla_trigger['e_py'] = []\n",
    "    tupla_trigger['e_pz']  = []\n",
    "    tupla_trigger['e_p'] = [] \n",
    "    tupla_trigger['e_ph'] = []\n",
    "    tupla_trigger['e_th']  = []    \n",
    "    tupla_trigger['SampFracEl25'] = []\n",
    "    tupla_trigger['SampFracEl20'] = []\n",
    "    tupla_trigger['TargTypeSM'] = [] ## RD's vertex cuts\n",
    "    tupla_trigger['TargType'] = []   ## Taisiya's vertex cuts (nominal)\n",
    "    tupla_trigger['h1_cm_ph'] = []\n",
    "    tupla_trigger['h1_cm_th'] = []\n",
    "    tupla_trigger['TargType'] = []\n",
    "    tupla_trigger['missing_mass'] = []\n",
    "    tupla_trigger['h1_ph'] = []\n",
    "    tupla_trigger['h1_th'] = []\n",
    "    tupla_trigger['h1_deltaZ'] = []\n",
    "    tupla_trigger['h1_Nphe'] = []\n",
    "    tupla_trigger['h1_Sector'] = []\n",
    "    tupla_trigger['h1_FidCut'] = []\n",
    "    tupla_trigger['h1_FidCutPiPlus'] = []\n",
    "    tupla_trigger['h1_Chi2CC'] = []\n",
    "    tupla_trigger['h1_StatCC'] = []\n",
    "    tupla_trigger['h1_T4'] = []\n",
    "    tupla_trigger['evnt'] = []\n",
    "    if not isMC:\n",
    "        tupla_trigger['run'] = []\n",
    "    \n",
    "    if include_truth:\n",
    "        mytree.mc_W = 0.938**2+mytree.mc_Nu*0.938*2-mytree.mc_Q2\n",
    "        \n",
    "    \n",
    "    start = time.time()\n",
    "    print('About to loop over ', mytree.GetEntries() , ' entries')\n",
    "    for ievt  in range(mytree.GetEntries()):\n",
    "        #print('evnt: ',ievt, 'len ParticlesFromPrevious ', (len(ParticlesFromPrevious)))\n",
    "        \n",
    "        #for kkk  in range (len(ParticlesFromPrevious)):\n",
    "        #    print('evnt',ievt, 'ParticlesFromPrevious, pid:', ParticlesFromPrevious[kkk].pid, 'zh: ', \n",
    "                   #ParticlesFromPrevious[kkk].Zh, 'W: ',ParticlesFromPrevious[kkk].W )\n",
    "        #if len(mytree.FidCheckCut) != len(mytree.Sector):\n",
    "        #    print('This shouldn\\'t ever happen: len(mytree.FidCheckCut) != len(mytree.Sector). Skipping event')\n",
    "        #    continue\n",
    "            \n",
    "        mytree.GetEntry(ievt)   \n",
    "        if mytree.W<2.05 or mytree.Q2<1.0: continue\n",
    "        \n",
    "        # by default we apply the loose vertex cuts (Hayk's) The other cases remains as variables\n",
    "        if ievt>maxevents: break        \n",
    "        if(mytree.TargTypeHH==1):\n",
    "            TargType=1\n",
    "        elif(mytree.TargTypeHH==2):\n",
    "            TargType=2\n",
    "        else:\n",
    "            TargType=0\n",
    "        #print (TargType,  ' ' , Target)\n",
    "        if not(isMC) and (TargType!=Target): continue ## 'Target' is a argument of this function\n",
    "                \n",
    "        #print('PASO all cuts')\n",
    "        W = mytree.W\n",
    "        Nu = mytree.Nu\n",
    "        #get electron momentum:\n",
    "        Pe = np.sqrt(mytree.Pex*mytree.Pex + mytree.Pey*mytree.Pey+ mytree.Pez*mytree.Pez)\n",
    "        scattered_e = ROOT.TLorentzVector()\n",
    "        scattered_e.SetPxPyPzE(mytree.Pex, mytree.Pey, mytree.Pez, Pe)\n",
    "        incoming_e = ROOT.TLorentzVector()\n",
    "        incoming_e.SetPxPyPzE(0,0,5.014,5.014)\n",
    "        virtual_photon  = incoming_e - scattered_e \n",
    "        virtual_photon_unitvector = virtual_photon.Vect().Unit()\n",
    "        proton = ROOT.TLorentzVector()\n",
    "        proton.SetPxPyPzE(0,0,0, 0.938)\n",
    "        \n",
    "        \n",
    "        if include_truth:\n",
    "            Nu_truth = mytree.mc_Nu\n",
    "            Pe_truth = np.sqrt(mytree.mc_Pex*mytree.mc_Pex + mytree.mc_Pey*mytree.mc_Pey+ mytree.mc_Pez*mytree.mc_Pez)\n",
    "            scattered_e_truth = ROOT.TLorentzVector()\n",
    "            scattered_e_truth.SetPxPyPzE(mytree.mc_Pex, mytree.mc_Pey, mytree.mc_Pez, Pe_truth)\n",
    "            virtual_photon_truth  = incoming_e - scattered_e_truth \n",
    "            virtual_photon_unitvector_truth = virtual_photon_truth.Vect().Unit()\n",
    "        run=0\n",
    "        if not isMC:\n",
    "            run = mytree.run\n",
    "        ## for each event the particles are saved in the 'particles' list.        \n",
    "        particles = []  ## this is how you define a list in python, this is created for each event\n",
    "        #print (' Entering main loop over particles')\n",
    "        for i in range(len(mytree.pid)):\n",
    "            #print(mytree.pid[i])\n",
    "            ## when the condition is true the 'continue' statement\n",
    "            ## takes me to the next iteration of the loop\n",
    "            if (abs(mytree.pid[i]) !=211 and mytree.pid[i]!=2212): continue \n",
    "                            \n",
    "            ## aplying the rest of cuts:\n",
    "            if ( mytree.P[i]<0.2 or mytree.ThetaLab[i]<10 or mytree.ThetaLab[i]>120 ):    continue\n",
    "            if ( mytree.pid[i]==-211 and (mytree.ThetaLab[i]>90 or mytree.ThetaLab[i]<25) ):    continue                \n",
    "            if ( mytree.pid[i]==-211 and mytree.ThetaLab[i]>40 and mytree.P[i]<0.2  ):    continue                \n",
    "            if ( mytree.pid[i]==-211 and mytree.ThetaLab[i]<40 and mytree.P[i]<0.5  ):    continue \n",
    "            if ( mytree.pid[i]==211  and mytree.P[i]>=3.0 and \n",
    "                (mytree.Nphe[i]<10 or mytree.Chi2CC[i]>0.0872 \n",
    "                 or mytree.StatCC[i]<=0 or mytree.NRowsCC[i]==0) ):    continue     \n",
    "  \n",
    "           \n",
    "            #print(mytree.pid[i])\n",
    "            i_lv = ROOT.TLorentzVector()    ## 4-vector of the hadron\n",
    "            i_lv.SetPxPyPzE(mytree.Px[i],mytree.Py[i],mytree.Pz[i],mytree.Zh[i]*Nu) \n",
    "            ## this is the 4-vector of the hadron\n",
    "            i_part = particle(mytree.pid[i], i_lv, virtual_photon, mytree.ThetaPQ[i] ) \n",
    "            \n",
    "            if include_truth:\n",
    "                i_lv_truth = ROOT.TLorentzVector()    ## 4-vector of the hadron\n",
    "                i_lv_truth.SetPxPyPzE(mytree.mc_Px[i],mytree.mc_Py[i],mytree.mc_Pz[i],mytree.mc_Zh[i]*Nu_truth) ## this is the 4-vector of the hadron\n",
    "                i_part_truth = particle(mytree.mc_pid[i], i_lv_truth, virtual_photon_truth, mytree.mc_ThetaPQ[i] ) ## particle is the class defined previously\n",
    "             \n",
    "            \n",
    "            \n",
    "            ## particle is the class defined previously\n",
    "            ## in this 'particles' list there are NO cuts applied (except the pid and obvious ones)\n",
    "            particles.append(i_part)   ## save that particle in the 'particles' list\n",
    "            X = (virtual_photon + proton -  i_part.LorentzVector) #unobserved hadronic system\n",
    "            #print('event:',ievt,'particle i:', i,' with PID:',  i_part.pid, 'and Zh:',\n",
    "            #       i_part.Zh, ', W: ',i_part.W)\n",
    "            if i_part.Zh > 0.4: #only save triggers and do correlations if they have z>0.4\n",
    "            #if i_part.Pt>1.0: #only save triggers if pT>1.0 \n",
    "            ## HERE WE SAVE THE VARIABLES FOR THE TRIGGER PARTICLE (THE ONE WITH Zh>0.4)\n",
    "                tupla_trigger['h1_pid'].append(i_part.pid)\n",
    "                if not isMC:\n",
    "                    tupla_trigger['run'].append(run)\n",
    "                tupla_trigger['h1_xf'].append(i_part.Xf)\n",
    "                tupla_trigger['h1_xf_default'].append(-1)\n",
    "                tupla_trigger['h1_z'].append(i_part.Zh)\n",
    "                tupla_trigger['h1_cm_pt'].append(i_part.Pt)\n",
    "                tupla_trigger['h1_rap'].append(i_part.y_star)\n",
    "                tupla_trigger['ycm'].append(i_part.ycm)\n",
    "                tupla_trigger['h1_cm_ph'].append(i_part.PhiPQ)\n",
    "                tupla_trigger['h1_cm_th'].append(i_part.ThetaPQ)\n",
    "                tupla_trigger['missing_mass'].append(X.M())\n",
    "                tupla_trigger['Q2'].append(mytree.Q2)\n",
    "                tupla_trigger['x'].append(mytree.Xb)\n",
    "                tupla_trigger['nu'].append(mytree.Nu)\n",
    "                tupla_trigger['W'].append(mytree.W)\n",
    "                tupla_trigger['e_px'].append(mytree.Pex)\n",
    "                tupla_trigger['e_py'].append(mytree.Pey)\n",
    "                tupla_trigger['e_pz'].append(mytree.Pez)\n",
    "                e_p = np.sqrt(mytree.Pex**2+mytree.Pey**2+mytree.Pez**2)\n",
    "                e_ph = np.arctan2(mytree.Pey,mytree.Pex)\n",
    "                e_th = np.arctan2(np.sqrt(mytree.Pex**2+mytree.Pey**2),mytree.Pez)\n",
    "                tupla_trigger['e_p'].append(e_p)\n",
    "                tupla_trigger['e_ph'].append(e_ph)\n",
    "                tupla_trigger['e_th'].append(e_th)\n",
    "                tupla_trigger['h1_T4'].append(mytree.T4[i])\n",
    "                tupla_trigger['SampFracEl25'].append(mytree.SampFractionEl25)\n",
    "                tupla_trigger['SampFracEl20'].append(mytree.SampFractionEl20)\n",
    "                tupla_trigger['TargTypeSM'].append(mytree.TargTypeSM)  ## RD's vertex cuts\n",
    "                tupla_trigger['TargType'].append(mytree.TargType)    ## Taisiya's vertex cuts (nominal)\n",
    "                tupla_trigger['h1_ph'].append(mytree.PhiLab[i])\n",
    "                tupla_trigger['h1_th'].append(mytree.ThetaLab[i])#i_part.LorentzVector.Theta())\n",
    "                #print 'mytree.Pt[i] ' , mytree.Pt[i], ' check: ' ,i_part.Vector.Perp(virtual_photon_unitvector)\n",
    "                \n",
    "                #print('Testing theta PQ', mytree.ThetaPQ[i],  ' '  , 180.0*i_part.ThetaPQ/np.pi)\n",
    "                #print('Testing phi PQ', mytree.PhiPQ[i],  ' '  , 180.0*i_part.PhiPQ/np.pi),Nphe,deltaZ\n",
    "                tupla_trigger['h1_deltaZ'].append(mytree.deltaZ[i])\n",
    "                tupla_trigger['h1_Nphe'].append(mytree.Nphe[i])\n",
    "                tupla_trigger['h1_Sector'].append(mytree.Sector[i])\n",
    "                tupla_trigger['h1_FidCut'].append(mytree.FidCheckCut[i])\n",
    "                tupla_trigger['h1_FidCutPiPlus'].append(mytree.FidCheckCutPiPlus[i])\n",
    "                tupla_trigger['h1_Chi2CC'].append(mytree.Chi2CC[i])\n",
    "                tupla_trigger['h1_StatCC'].append(mytree.StatCC[i])\n",
    "                tupla_trigger['evnt'].append(mytree.evnt)\n",
    "                \n",
    "                for j in range(len(mytree.pid)): \n",
    "                    if i==j: continue\n",
    "                    pass_recon=True\n",
    "                    if (abs(mytree.pid[j]) !=211 and mytree.pid[j]!=2212): pass_recon=False\n",
    "                    #print('evnt', ievt,' j:', j, ' , lenpid:',len(mytree.pid) )\n",
    "                    ## aplying the rest of cuts:\n",
    "                    if ( mytree.P[j]<0.2 or mytree.ThetaLab[j]<10 or mytree.ThetaLab[j]>120 ):    pass_recon=False\n",
    "                    if ( mytree.pid[j]==-211 and (mytree.ThetaLab[j]>90 or mytree.ThetaLab[j]<25) ):    pass_recon=False                \n",
    "                    if ( mytree.pid[j]==-211 and mytree.ThetaLab[j]>40 and mytree.P[j]<0.2  ):    pass_recon=False                \n",
    "                    if ( mytree.pid[j]==-211 and mytree.ThetaLab[j]<40 and mytree.P[j]<0.5  ):    pass_recon=False \n",
    "                    if ( mytree.pid[j]==211  and mytree.P[j]>=3.0 and \n",
    "                        (mytree.Nphe[j]<5 or mytree.Chi2CC[j]>0.0872 or mytree.StatCC[j]<=0 or \n",
    "                         mytree.NRowsCC[j]==0) ):    pass_recon=False  \n",
    "                    if not pass_recon:\n",
    "                        if not keepH2FailRecon:\n",
    "                            continue\n",
    "                            \n",
    "                        if (abs(mytree.mc_pid[j]) !=211 and mytree.mc_pid[j]!=2212): continue\n",
    "                        \n",
    "                        if h2CutsTruth:\n",
    "                            #print('evnt', ievt,' j:', j, ' , lenpid:',len(mytree.pid) )\n",
    "                            ## aplying the rest of cuts:\n",
    "                            if ( mytree.mc_P[j]<0.2 or mytree.mc_ThetaLab[j]<10 or mytree.mc_ThetaLab[j]>120 ):    continue\n",
    "                            if ( mytree.mc_pid[j]==-211 and (mytree.mc_ThetaLab[j]>90 or mytree.mc_ThetaLab[j]<25) ):    continue                \n",
    "                            if ( mytree.mc_pid[j]==-211 and mytree.mc_ThetaLab[j]>40 and mytree.mc_P[j]<0.2  ):    continue                \n",
    "                            if ( mytree.mc_pid[j]==-211 and mytree.mc_ThetaLab[j]<40 and mytree.mc_P[j]<0.5  ):    continue \n",
    "                        #if ( mytree.mc_pid[j]==211  and mytree.mc_P[j]>=3.0 and \n",
    "                        #    (mytree.Nphe[j]<10 or mytree.Chi2CC[j]>0.0872 or mytree.StatCC[j]<=0 or \n",
    "                        #     mytree.NRowsCC[j]==0) ):    continue  \n",
    "                    #if (SampFractionEl==0):    continue\n",
    "                    #print('inside j loop')\n",
    "                    \n",
    "                    \n",
    "                    j_lv = ROOT.TLorentzVector()    \n",
    "                    j_lv.SetPxPyPzE(mytree.Px[j],mytree.Py[j],mytree.Pz[j],mytree.Zh[j]*Nu)\n",
    "                    j_part = particle(mytree.pid[j], j_lv, virtual_photon, mytree.ThetaPQ[j] )\n",
    "                    ## particle is the defined class\n",
    "                    if include_truth:\n",
    "                        j_lv_truth = ROOT.TLorentzVector()    ## 4-vector of the hadron\n",
    "                        j_lv_truth.SetPxPyPzE(mytree.mc_Px[j],mytree.mc_Py[j],mytree.mc_Pz[j],mytree.mc_Zh[j]*Nu_truth) ## this is the 4-vector of the hadron\n",
    "                        j_part_truth = particle(mytree.mc_pid[j], j_lv_truth, virtual_photon_truth, mytree.mc_ThetaPQ[j] ) ## particle is the class defined previously\n",
    "                        dphi_truth = abs(ROOT.TVector2.Phi_mpi_pi(i_part_truth.PhiPQ-j_part_truth.PhiPQ))  \n",
    "                        dphi_lab_truth = abs(ROOT.TVector2.Phi_mpi_pi(i_part_truth.PhiLab-j_part_truth.PhiLab))\n",
    "                        dy_truth = i_part_truth.y-j_part_truth.y\n",
    "                        deta_truth = dy_truth\n",
    "                        \n",
    "                        dihadron_truth = i_part_truth.LorentzVector+j_part_truth.LorentzVector  ## LorentzVector is a method of the \n",
    "                                    #particle class, is the '4-vector' of the particle, 3rd argument of the class\n",
    "                    \n",
    "                        X_truth = (virtual_photon_truth + proton - dihadron_truth) #unobserved hadronic system\n",
    "                        X1_truth = (virtual_photon_truth + proton - i_part_truth.LorentzVector)\n",
    "                        X2_truth = (virtual_photon_truth + proton - j_part_truth.LorentzVector)\n",
    "                    \n",
    "                    \n",
    "                    ## TVector2.Phi_mpi_pi is a built in function of TVector2 class (2D vectors).\n",
    "                    ## Returns Phi angle in the interval [-pi,pi]. \n",
    "                    ## Also, we used the 'abs' to obtain the 0->pi range\n",
    "                    \n",
    "                    dphi = abs(ROOT.TVector2.Phi_mpi_pi(i_part.PhiPQ-j_part.PhiPQ))  \n",
    "                    dphi_lab = abs(ROOT.TVector2.Phi_mpi_pi(i_part.PhiLab-j_part.PhiLab))\n",
    "                    \n",
    "                    dy = i_part.y-j_part.y  ## i_part and j_part are object of the class particles \n",
    "                                            # and 'y' is a method, is the rapidity in the lab frame\n",
    "                    deta = dy\n",
    "                    ## Di-hadron 4-vector, is the sum P_{di-hadron} = P_{trigger-hadron} + P_{other-hadron}\n",
    "                    dipion = i_part.LorentzVector+j_part.LorentzVector  ## LorentzVector is a method of the \n",
    "                                    #particle class, is the '4-vector' of the particle, 3rd argument of the class\n",
    "                    \n",
    "                    X  = (virtual_photon + proton - dipion) #unobserved hadronic system\n",
    "                    X1 = (virtual_photon + proton - i_part.LorentzVector)\n",
    "                    X2 = (virtual_photon + proton - j_part.LorentzVector)\n",
    "                    \n",
    "                    ## note: drap is h1_rap - h2_rap\n",
    "                    tupla['dphi'].append(dphi) ## phiPQ(i) - phiPQ(j)\n",
    "                    tupla['dphi_lab'].append(dphi_lab)\n",
    "                    tupla['drap'].append(dy)         ## This is in lab frame -> dy = y_lab(i) - y_lab(j)\n",
    "                    tupla['h1_z'].append(i_part.Zh)\n",
    "                    tupla['h2_z'].append(j_part.Zh)\n",
    "                    tupla['h1_cm_pt'].append(i_part.Pt)\n",
    "                    tupla['h2_cm_pt'].append(j_part.Pt)\n",
    "                    tupla['h1_xf'].append(i_part.Xf)\n",
    "                    tupla['h2_xf'].append(j_part.Xf)\n",
    "                    tupla['h1_rap'].append(i_part.y_star)  ## y_star = y(lab) - y(cm)\n",
    "                    tupla['ycm'].append(i_part.ycm)\n",
    "                    tupla['h2_rap'].append(j_part.y_star)\n",
    "                    tupla['h1_pid'].append(i_part.pid)\n",
    "                    tupla['h2_pid'].append(j_part.pid)\n",
    "                    tupla['h1_cm_ph'].append(i_part.PhiPQ)\n",
    "                    tupla['h2_cm_ph'].append(j_part.PhiPQ)\n",
    "                    tupla['h1_cm_th'].append(i_part.ThetaPQ)\n",
    "                    tupla['h2_cm_th'].append(j_part.ThetaPQ)\n",
    "                    tupla['pair_mass'].append(dipion.M())\n",
    "                    tupla['pair_pt'].append( dipion.Vect().Perp(virtual_photon_unitvector))\n",
    "                    tupla['mx_eh1h2x'].append(X.M())\n",
    "                    tupla['mx_eh1x'].append(X1.M())\n",
    "                    tupla['mx_eh2x'].append(X2.M())\n",
    "                    tupla['t'].append( -(virtual_photon- dipion).M2())\n",
    "                    tupla['Q2'].append(mytree.Q2)\n",
    "                    tupla['x'].append(mytree.Xb)\n",
    "                    tupla['nu'].append(mytree.Nu)\n",
    "                    tupla['W'].append(mytree.W)\n",
    "                    tupla['SampFracEl25'].append(mytree.SampFractionEl25)\n",
    "                    tupla['SampFracEl20'].append(mytree.SampFractionEl20)\n",
    "                    tupla['TargTypeSM'].append(mytree.TargTypeSM)  ## RD's vertex cuts\n",
    "                    tupla['TargType'].append(mytree.TargType)    ## Taisiya's vertex cuts (nominal)\n",
    "                    tupla['u'].append(-(scattered_e-proton).M2())\n",
    "                    tupla['h1_ph'].append(mytree.PhiLab[i])\n",
    "                    tupla['h1_th'].append(mytree.ThetaLab[i])\n",
    "                    tupla['h2_ph'].append(mytree.PhiLab[j])\n",
    "                    tupla['h2_th'].append(mytree.ThetaLab[j])\n",
    "                    tupla['h1_deltaZ'].append(mytree.deltaZ[i])\n",
    "                    tupla['h2_deltaZ'].append(mytree.deltaZ[j])\n",
    "                    tupla['h1_Nphe'].append(mytree.Nphe[i])\n",
    "                    tupla['h1_Sector'].append(mytree.Sector[i])\n",
    "                    if not isMC:\n",
    "                        tupla['run'].append(run)\n",
    "                    #if(len(mytree.FidCheckCut[i] )==len(mytree.FidCheckCut[i] )):\n",
    "                    #    tupla['h1_FidCut'].append(mytree.FidCheckCut[i])\n",
    "                    #else:\n",
    "                    #    print('this should never happen:  len(mytree.FidCheckCut)!=len(mytree.FidCheckCutPiPlus)')                    \n",
    "                    tupla['h1_FidCutPiPlus'].append(mytree.FidCheckCutPiPlus[i])\n",
    "                    tupla['h2_Nphe'].append(mytree.Nphe[j])\n",
    "                    tupla['h2_Sector'].append(mytree.Sector[j])\n",
    "                    tupla['h1_FidCut'].append(mytree.FidCheckCut[i])\n",
    "                    tupla['h2_FidCut'].append(mytree.FidCheckCut[j]) \n",
    "                    tupla['h2_FidCutPiPlus'].append(mytree.FidCheckCutPiPlus[j])                    \n",
    "                    tupla['h1_Chi2CC'].append(mytree.Chi2CC[i])\n",
    "                    tupla['h1_StatCC'].append(mytree.StatCC[i])\n",
    "                    tupla['h2_Chi2CC'].append(mytree.Chi2CC[j])\n",
    "                    tupla['h2_StatCC'].append(mytree.StatCC[j])\n",
    "                    tupla['h1_Betta'].append(mytree.Betta[i])\n",
    "                    tupla['h2_Betta'].append(mytree.Betta[j])\n",
    "                    tupla['h1_T4'].append(mytree.T4[i])\n",
    "                    tupla['h2_T4'].append(mytree.T4[j])\n",
    "                    tupla['evnt'].append(mytree.evnt)\n",
    "                    \n",
    "                    tupla['e_px'].append(mytree.Pex)\n",
    "                    tupla['e_py'].append(mytree.Pey)\n",
    "                    tupla['e_pz'].append(mytree.Pez)\n",
    "                    tupla['e_p'].append(e_p)\n",
    "                    tupla['e_ph'].append(e_ph)\n",
    "                    tupla['e_th'].append(e_th)\n",
    "                    \n",
    "                    if keepH2FailRecon:\n",
    "                        tupla['pass_recon'].append(1 if pass_recon else 0)\n",
    "                    \n",
    "                    \n",
    "                    if include_truth:\n",
    "                        tupla['dphi_truth'].append(dphi_truth)\n",
    "                        tupla['dphi_lab_truth'].append(dphi_lab_truth)\n",
    "                        tupla['drap_truth'].append(dy_truth)\n",
    "                        tupla['h1_truth_z'].append(i_part_truth.Zh)\n",
    "                        tupla['h2_truth_z'].append(j_part_truth.Zh)\n",
    "                        tupla['h1_truth_cm_pt'].append(i_part_truth.Pt)\n",
    "                        tupla['h2_truth_cm_pt'].append(j_part_truth.Pt)\n",
    "                        tupla['h1_truth_xf'].append(i_part_truth.Xf)\n",
    "                        tupla['h2_truth_xf'].append(j_part_truth.Xf)\n",
    "                        tupla['h1_truth_rap'].append(i_part_truth.y_star)\n",
    "                        tupla['ycm_truth'].append(i_part_truth.ycm)\n",
    "                        tupla['h2_truth_rap'].append(j_part_truth.y_star)\n",
    "                        tupla['h1_truth_pid'].append(i_part_truth.pid)\n",
    "                        tupla['h2_truth_pid'].append(j_part_truth.pid)\n",
    "                        tupla['h1_truth_cm_ph'].append(i_part_truth.PhiPQ)\n",
    "                        tupla['h2_truth_cm_ph'].append(j_part_truth.PhiPQ)\n",
    "                        tupla['h1_truth_cm_th'].append(i_part_truth.ThetaPQ)\n",
    "                        tupla['h2_truth_cm_th'].append(j_part_truth.ThetaPQ)\n",
    "                        tupla['pair_mass_truth'].append(dihadron_truth.M())\n",
    "                        tupla['pair_pt_truth'].append( dihadron_truth.Vect().Perp(virtual_photon_unitvector_truth))\n",
    "                        tupla['mx_eh1h2x_truth'].append(X_truth.M())\n",
    "                        tupla['mx_eh1x_truth'].append(X1_truth.M())\n",
    "                        tupla['mx_eh2x_truth'].append(X2_truth.M())\n",
    "                        tupla['t_truth'].append( -(virtual_photon_truth- dihadron_truth).M2())\n",
    "                        \n",
    "                        tupla['Q2_truth'].append(mytree.mc_Q2)\n",
    "                        tupla['x_truth'].append(mytree.mc_Xb)\n",
    "                        tupla['nu_truth'].append(mytree.mc_Nu)\n",
    "                        tupla['W_truth'].append(mytree.mc_W)\n",
    "                        tupla['u_truth'].append(-(scattered_e_truth-proton).M2())\n",
    "                        tupla['h1_truth_ph'].append(mytree.mc_PhiLab[i])\n",
    "                        tupla['h1_truth_th'].append(mytree.mc_ThetaLab[i])\n",
    "                        tupla['h2_truth_ph'].append(mytree.mc_PhiLab[j])\n",
    "                        tupla['h2_truth_th'].append(mytree.mc_ThetaLab[j])\n",
    "                        tupla['e_truth_px'].append(mytree.Pex)\n",
    "                        tupla['e_truth_py'].append(mytree.Pey)\n",
    "                        tupla['e_truth_pz'].append(mytree.Pez)\n",
    "                        e_truth_p = np.sqrt(mytree.mc_Pex**2+mytree.mc_Pey**2+mytree.mc_Pez**2)\n",
    "                        e_truth_ph = np.arctan2(mytree.mc_Pey,mytree.mc_Pex)\n",
    "                        e_truth_th = np.arctan2(np.sqrt(mytree.mc_Pex**2+mytree.mc_Pey**2),mytree.mc_Pez)\n",
    "                        tupla['e_truth_p'].append(e_truth_p)\n",
    "                        tupla['e_truth_ph'].append(e_truth_ph)\n",
    "                        tupla['e_truth_th'].append(e_truth_th)\n",
    "                                            \n",
    "         #end loop over secondary loop    \n",
    "                \n",
    "                ## here we are still under the condition of Zh>0.4\n",
    "                #print(ievt,i,j)\n",
    "                #print('')\n",
    "                for mixparticle in ParticlesFromPrevious: ## ParticlesFromPrevious is a list \n",
    "                                                          ## with 'particle' class objects\n",
    "                    #print('\\ninside mixparticle loop\\n')\n",
    "                    #print('i: ',i,'mixparticles pid:',mixparticle.pid,' zh :', mixparticle.Zh , ', W: ', \n",
    "                           #mixparticle.W, ' i_part Zh:', i_part.Zh, 'i_part.W: ',i_part.W)\n",
    "                    dphi = abs(ROOT.TVector2.Phi_mpi_pi(i_part.PhiPQ-mixparticle.PhiPQ))\n",
    "                    tupla_mix['dphi_norot'].append(dphi)\n",
    "                    tupla_mix['h2_cm_ph_norot'].append(mixparticle.PhiPQ)\n",
    "                    tupla_mix['h2_cm_th_norot'].append(mixparticle.ThetaPQ)\n",
    "                    if not isMC:\n",
    "                        tupla_mix['run'].append(run)\n",
    "                    mixparticle.redefine(virtual_photon) \n",
    "                    #recalculates variables in this' event photon frame (not in the previous one)\n",
    "                    #dphi = abs(ROOT.TVector2.Phi_mpi_pi(i_part.PhiPQ-mixparticle.PhiPQ))\n",
    "                    #print 'dphi_pq after redefinition: ', dphi , ' phi_pq ', mixparticle.PhiPQ\n",
    "                    \n",
    "                    dipion = i_part.LorentzVector+mixparticle.LorentzVector\n",
    "                    X  = (virtual_photon + proton - dipion)\n",
    "                    X1 = (virtual_photon + proton - i_part.LorentzVector)\n",
    "                    X2 = (virtual_photon + proton - mixparticle.LorentzVector)\n",
    "\n",
    "                    #recalculate the phi_pq. It has to be with respect to the photon direction\n",
    "                    \n",
    "                    dphi = abs(ROOT.TVector2.Phi_mpi_pi(i_part.PhiPQ-mixparticle.PhiPQ))\n",
    "                    dphi_lab = abs(ROOT.TVector2.Phi_mpi_pi(i_part.PhiLab-mixparticle.PhiLab))\n",
    "\n",
    "                    dy = i_part.y-mixparticle.y\n",
    "                    deta = dy#i_part.ThetaPQ-mixparticle.ThetaPQ\n",
    "                    tupla_mix['dphi'].append(dphi)\n",
    "                    tupla_mix['dphi_lab'].append(dphi_lab)\n",
    "                    tupla_mix['drap'].append(dy)\n",
    "                    tupla_mix['h1_z'].append(i_part.Zh)\n",
    "                    tupla_mix['h2_z'].append(mixparticle.Zh)\n",
    "                    tupla_mix['h1_cm_pt'].append(i_part.Pt)\n",
    "                    tupla_mix['h2_cm_pt'].append(mixparticle.Pt)\n",
    "                    tupla_mix['h1_xf'].append(i_part.Xf)\n",
    "                    tupla_mix['h2_xf'].append(mixparticle.Xf)\n",
    "                    tupla_mix['h1_rap'].append(i_part.y_star)\n",
    "                    tupla_mix['ycm'].append(i_part.ycm)\n",
    "                    tupla_mix['h2_rap'].append(mixparticle.y_star)\n",
    "                    tupla_mix['h1_pid'].append(i_part.pid)\n",
    "                    tupla_mix['h2_pid'].append(mixparticle.pid)\n",
    "                    tupla_mix['h1_cm_ph'].append(i_part.PhiPQ)\n",
    "                    tupla_mix['h2_cm_ph'].append(mixparticle.PhiPQ)\n",
    "                    tupla_mix['h1_cm_th'].append(i_part.ThetaPQ)\n",
    "                    tupla_mix['h2_cm_th'].append(mixparticle.ThetaPQ)\n",
    "                    tupla_mix['pair_mass'].append(dipion.M())\n",
    "                    tupla_mix['pair_pt'].append( dipion.Vect().Perp(virtual_photon_unitvector))\n",
    "                    tupla_mix['mx_eh1h2x'].append(X.M())\n",
    "                    tupla_mix['mx_eh1x'].append(X1.M())\n",
    "                    tupla_mix['mx_eh2x'].append(X2.M())\n",
    "                    tupla_mix['t'].append( -(virtual_photon- dipion).M2())\n",
    "                    tupla_mix['Q2'].append(mytree.Q2)\n",
    "                    tupla_mix['x'].append(mytree.Xb)\n",
    "                    tupla_mix['nu'].append(mytree.Nu)\n",
    "                    tupla_mix['W'].append(mytree.W)\n",
    "                    tupla_mix['SampFracEl25'].append(mytree.SampFractionEl25)\n",
    "                    tupla_mix['SampFracEl20'].append(mytree.SampFractionEl20)\n",
    "                    tupla_mix['TargTypeSM'].append(mytree.TargTypeSM)  ## RD's vertex cuts\n",
    "                    tupla_mix['TargType'].append(mytree.TargType)    ## Taisiya's vertex cuts (nominal)\n",
    "                    tupla_mix['u'].append(-(scattered_e-proton).M2())\n",
    "                    tupla_mix['h1_ph'].append(i_part.LorentzVector.Phi())\n",
    "                    tupla_mix['h1_th'].append(mytree.ThetaLab[i])\n",
    "                    tupla_mix['h2_ph'].append(mixparticle.LorentzVector.Phi())\n",
    "                    tupla_mix['h2_th'].append(mytree.ThetaLab[j])\n",
    "                    tupla_mix['h1_deltaZ'].append(mytree.deltaZ[i])\n",
    "                    tupla_mix['h2_deltaZ'].append(mytree.deltaZ[j])\n",
    "                    tupla_mix['h1_Nphe'].append(mytree.Nphe[i])\n",
    "                    tupla_mix['h1_Sector'].append(mytree.Sector[i])\n",
    "                    tupla_mix['h1_FidCut'].append(mytree.FidCheckCut[i])\n",
    "                    tupla_mix['h1_FidCutPiPlus'].append(mytree.FidCheckCutPiPlus[i])\n",
    "                    tupla_mix['h2_Nphe'].append(mytree.Nphe[j])\n",
    "                    tupla_mix['h2_Sector'].append(mytree.Sector[j])\n",
    "                    tupla_mix['h2_FidCut'].append(mytree.FidCheckCut[j])\n",
    "                    tupla_mix['h2_FidCutPiPlus'].append(mytree.FidCheckCutPiPlus[j])\n",
    "                    tupla_mix['h1_Chi2CC'].append(mytree.Chi2CC[i])\n",
    "                    tupla_mix['h1_StatCC'].append(mytree.StatCC[i])\n",
    "                    tupla_mix['h2_Chi2CC'].append(mytree.Chi2CC[j])\n",
    "                    tupla_mix['h2_StatCC'].append(mytree.StatCC[j])\n",
    "                    tupla_mix['evnt'].append(mytree.evnt)\n",
    "                    #for kk  in range (len(ParticlesFromPrevious)):\n",
    "                        #print('ParticlesFromPrevious, pid:', ParticlesFromPrevious[kk].pid, 'zh: ', \n",
    "                               #ParticlesFromPrevious[kk].Zh, 'W: ',ParticlesFromPrevious[kk].W )\n",
    "        #print (' Exiting main loop over particles (i loop, not over all entries)')\n",
    "        ParticlesFromPrevious = particles\n",
    "        #print ' going for next event'    \n",
    "        #print ' particles in event', len(particles\n",
    "        ##end loop over events correlations    \n",
    "    end = time.time()\n",
    "    print ('Processed in',  end-start, 'seconds')\n",
    "    ##printing the 3 tuples to the output file\n",
    "    df = pd.DataFrame(tupla)\n",
    "    df_mix= pd.DataFrame(tupla_mix)\n",
    "    df_trigger = pd.DataFrame(tupla_trigger)\n",
    "    print ('Number of triggers with z>0.4,  ', df.query('h1_z>0.4').shape[0])\n",
    "    print ('Number of pairs with z>0.4, '    , df_trigger.query('h1_z>0.4').shape[0]) \n",
    "    myfile.Close()\n",
    "    return df, df_mix, df_trigger        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here we defined some dictionaries ({})\n",
    "df = {}\n",
    "df_mc = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1e+03 ns, total: 2 µs\n",
      "Wall time: 4.05 µs\n",
      "done with:  0  files\n",
      "/home/sebouh/di-hadron/data/P27/ca/C.root  has  23112079  entries\n",
      "About to loop over  23112079  entries\n",
      "Processed in 2439.0616698265076 seconds\n",
      "Number of triggers with z>0.4,   1643292\n",
      "Number of pairs with z>0.4,  2744692\n",
      "/home/sebouh/di-hadron/data/P27/ca/C.root  has  23112079  entries\n",
      "About to loop over  23112079  entries\n",
      "Processed in 2546.5679817199707 seconds\n",
      "Number of triggers with z>0.4,   1456232\n",
      "Number of pairs with z>0.4,  3017886\n",
      "end\n",
      "TFile: name=/home/sebouh/di-hadron/data/P27/ca/C.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/data/P27/ca/C.root, title=, option=READ\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"eefda547-2a9f-4604-938a-a3e6eb16f0fc\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"eefda547-2a9f-4604-938a-a3e6eb16f0fc\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFile: name=/home/sebouh/di-hadron/data/P27/ca/C.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/data/P27/ca/C.root, title=, option=READ\n"
     ]
    }
   ],
   "source": [
    "%%notify\n",
    "%time\n",
    "\n",
    "df['Pb'],df['Pb_mix'], df['Pb_trigger'] = [None,None,None]\n",
    "df['D_Pb'],df['D_Pb_mix'], df['D_Pb_trigger'] = [None,None,None]\n",
    "df['Fe'],df['Fe_mix'], df['Fe_trigger'] = [None,None,None]\n",
    "df['D_Fe'],df['D_Fe_mix'], df['D_Fe_trigger'] = [None,None,None]\n",
    "df['C'],df['C_mix'], df['C_trigger'] = [None,None,None]\n",
    "df['D_C'],df['D_C_mix'], df['D_C_trigger'] = [None,None,None]\n",
    "path = '/home/sebouh/di-hadron/data/P27/ca/'\n",
    "#path='/home/seba/'\n",
    "tar='C'\n",
    "Files = listdir(path) \n",
    "count=0\n",
    "for name in Files:\n",
    "    filename = path+name\n",
    "    print ('done with: ', count, ' files')\n",
    "    count=count+1\n",
    "    if( '.root' not in name): continue \n",
    "    pairs, pairs_mix, trigger = getDataframes(filename,Target=2) ## getDataframes is a function just created\n",
    "    df[tar] = pd.concat([ df[tar], pairs])\n",
    "    df['%s_mix'%tar] = pd.concat([ df['%s_mix'%tar], pairs_mix])\n",
    "    df['%s_trigger'%tar] = pd.concat([ df['%s_trigger'%tar], trigger])\n",
    "    pairs, pairs_mix, trigger = getDataframes(filename,Target=1) ## getDataframes is a function just created\n",
    "    df['D_%s'%tar] = pd.concat([ df['D_%s'%tar], pairs])\n",
    "    df['D_%s_mix'%tar] = pd.concat([ df['D_%s_mix'%tar], pairs_mix])\n",
    "    df['D_%s_trigger'%tar] = pd.concat([ df['D_%s_trigger'%tar], trigger])\n",
    "tar = \"C\"\n",
    "root_pandas.to_root_multi('Data_Pairs_%s.root'%tar, {a:df[a] for a in f\"{tar} D_{tar} {tar}_trigger D_{tar}_trigger {tar}_mix D_{tar}_mix\".split()})\n",
    "\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with:  0  files\n",
      "/home/sebouh/di-hadron/data/P27/fe/Fe.root  has  35058567  entries\n",
      "About to loop over  35058567  entries\n",
      "Processed in 3890.9129753112793 seconds\n",
      "Number of triggers with z>0.4,   2768303\n",
      "Number of pairs with z>0.4,  4175621\n",
      "/home/sebouh/di-hadron/data/P27/fe/Fe.root  has  35058567  entries\n",
      "About to loop over  35058567  entries\n",
      "Processed in 3674.2370727062225 seconds\n",
      "Number of triggers with z>0.4,   2114873\n",
      "Number of pairs with z>0.4,  4462608\n",
      "end\n",
      "TFile: name=/home/sebouh/di-hadron/data/P27/fe/Fe.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/data/P27/fe/Fe.root, title=, option=READ\n"
     ]
    }
   ],
   "source": [
    "path = '/home/sebouh/di-hadron/data/P27/fe/'\n",
    "#path='/home/seba/'\n",
    "tar='Fe'\n",
    "Files = listdir(path) \n",
    "count=0\n",
    "for name in Files:\n",
    "    filename = path+name\n",
    "    print ('done with: ', count, ' files')\n",
    "    count=count+1\n",
    "    if( '.root' not in name): continue \n",
    "    pairs, pairs_mix, trigger = getDataframes(filename,Target=2) ## getDataframes is a function just created\n",
    "    df[tar] = pd.concat([ df[tar], pairs])\n",
    "    df['%s_mix'%tar] = pd.concat([ df['%s_mix'%tar], pairs_mix])\n",
    "    df['%s_trigger'%tar] = pd.concat([ df['%s_trigger'%tar], trigger])\n",
    "    pairs, pairs_mix, trigger = getDataframes(filename,Target=1) ## getDataframes is a function just created\n",
    "    df['D_%s'%tar] = pd.concat([ df['D_%s'%tar], pairs])\n",
    "    df['D_%s_mix'%tar] = pd.concat([ df['D_%s_mix'%tar], pairs_mix])\n",
    "    df['D_%s_trigger'%tar] = pd.concat([ df['D_%s_trigger'%tar], trigger])\n",
    "tar = \"Fe\"\n",
    "root_pandas.to_root_multi('Data_Pairs_%s.root'%tar, {a:df[a] for a in f\"{tar} D_{tar} {tar}_trigger D_{tar}_trigger {tar}_mix D_{tar}_mix\".split()})\n",
    "\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with:  0  files\n",
      "/home/sebouh/di-hadron/data/P27/pb/Pb.root  has  26960616  entries\n",
      "About to loop over  26960616  entries\n",
      "Processed in 1900.1304955482483 seconds\n",
      "Number of triggers with z>0.4,   1220015\n",
      "Number of pairs with z>0.4,  1854656\n",
      "/home/sebouh/di-hadron/data/P27/pb/Pb.root  has  26960616  entries\n",
      "About to loop over  26960616  entries\n",
      "Processed in 3744.0610489845276 seconds\n",
      "Number of triggers with z>0.4,   2209208\n",
      "Number of pairs with z>0.4,  4635633\n",
      "end\n",
      "TFile: name=/home/sebouh/di-hadron/data/P27/pb/Pb.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/data/P27/pb/Pb.root, title=, option=READ\n"
     ]
    }
   ],
   "source": [
    "path = '/home/sebouh/di-hadron/data/P27/pb/'\n",
    "#path='/home/seba/'\n",
    "tar='Pb'\n",
    "Files = listdir(path) \n",
    "count=0\n",
    "for name in Files:\n",
    "    filename = path+name\n",
    "    print ('done with: ', count, ' files')\n",
    "    count=count+1\n",
    "    if( '.root' not in name): continue \n",
    "    pairs, pairs_mix, trigger = getDataframes(filename,Target=2) ## getDataframes is a function just created\n",
    "    df[tar] = pd.concat([ df[tar], pairs])\n",
    "    df['%s_mix'%tar] = pd.concat([ df['%s_mix'%tar], pairs_mix])\n",
    "    df['%s_trigger'%tar] = pd.concat([ df['%s_trigger'%tar], trigger])\n",
    "    pairs, pairs_mix, trigger = getDataframes(filename,Target=1) ## getDataframes is a function just created\n",
    "    df['D_%s'%tar] = pd.concat([ df['D_%s'%tar], pairs])\n",
    "    df['D_%s_mix'%tar] = pd.concat([ df['D_%s_mix'%tar], pairs_mix])\n",
    "    df['D_%s_trigger'%tar] = pd.concat([ df['D_%s_trigger'%tar], trigger])\n",
    "tar = \"Pb\"\n",
    "root_pandas.to_root_multi('Data_Pairs_%s.root'%tar, {a:df[a] for a in f\"{tar} D_{tar} {tar}_trigger D_{tar}_trigger {tar}_mix D_{tar}_mix\".split()})\n",
    "\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tar = \"C\"\n",
    "root_pandas.to_root_multi('Data_Pairs_%s.root'%tar, {a:df[a] for a in f\"{tar} D_{tar} {tar}_trigger D_{tar}_trigger {tar}_mix D_{tar}_mix\".split()})\n",
    "#    print('Entries in the dataframe so far are ', df['D_Fe'].shape[0])\n",
    "#    print('Entries in the MIXED dataframe so far are ', df['D_Fe_mix'].shape[0])\n",
    "#    print('Entries in the trigger dataframe so far are ', df['D_Fe_trigger'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2114873"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## this is equivalent to: D_Fe->Draw(\"h1_ph>>h(100,0,1)\"), ok!\n",
    "#plt.hist(df['D_Fe']['h1_ph'],bins=100,range=(0,1.0))\n",
    "#df['D_Fe'].shape[0]  ## shape[0] return the number of rows of the array (number electrons)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['D_C'].query('h2_z>0.2').hist(figsize=(20,20),bins=100,\n",
    "#column=['dphi_lab','dphi','h1_ph','h2_ph','h1_cm_ph','h2_cm_ph'])\n",
    "#plt.savefig('plot_test.png', bbox_inches='tight')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-aa06850c7bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df['Pb'].query('h2_z>0.2').hist(figsize=(20,20),bins=100,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                       column=['h1_cm_pt','dphi_lab','dphi','h1_ph','h2_ph',\n\u001b[1;32m      3\u001b[0m                                               'h1_cm_ph','h2_cm_ph','h2_pid'])\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#plt.savefig('plot_test2.png', bbox_inches='tight')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'query'"
     ]
    }
   ],
   "source": [
    "#df['Pb'].query('h2_z>0.2').hist(figsize=(20,20),bins=100,\n",
    "#                                      column=['h1_cm_pt','dphi_lab','dphi','h1_ph','h2_ph',\n",
    "#                                              'h1_cm_ph','h2_cm_ph','h2_pid'])\n",
    "#plt.savefig('plot_test2.png', bbox_inches='tight')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#def to_root(df,filename, treename):\n",
    "#    with uproot3.recreate(filename) as f:\n",
    "#        f[treename] = uproot3.newtree({col:df[col].dtype for col in df.columns})\n",
    "#        f[treename].extend(dict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7f8419606e5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroot_pandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_root_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data_Pairs_%s.root'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "root_pandas.to_root_multi('Data_Pairs_%s.root'%tar, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hadd Target file: P27_Pairs_Fe.root\n",
      "hadd compression setting for all output: 1\n",
      "hadd Source file 1: tmp_D_Fe.root\n",
      "hadd Source file 2: tmp_D_Fe_mix.root\n",
      "hadd Source file 3: tmp_D_Fe_trigger.root\n",
      "hadd Source file 4: tmp_Fe.root\n",
      "hadd Source file 5: tmp_Fe_mix.root\n",
      "hadd Source file 6: tmp_Fe_trigger.root\n",
      "hadd Target path: P27_Pairs_Fe.root:/\n",
      "Error in <TFile::WriteBuffer>: error writing all requested bytes to file P27_Pairs_Fe.root, wrote 21585601 of 27088471\n",
      "SysError in <TFile::WriteBuffer>: error writing to file P27_Pairs_Fe.root (-1) (No space left on device)\n",
      "Warning in <TTreeCloner::TTreeCloner>: The output TTree (Fe_trigger) must be associated with a writable file (P27_Pairs_Fe.root).\n",
      "Error in <TFileMerger::Merge>: error during merge of your ROOT files\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"b542f50e-064f-42a8-855f-5c66d8f7b2fb\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"b542f50e-064f-42a8-855f-5c66d8f7b2fb\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "tar='Fe'\n",
    "outName='P27_Pairs_%s.root'%tar\n",
    "\n",
    "def to_root(df,filename, treename):\n",
    "    with uproot3.recreate(filename) as f:\n",
    "        f[treename] = uproot3.newtree({col:df[col].dtype for col in df.columns})\n",
    "        f[treename].extend(dict(df))\n",
    "\n",
    "to_root(df['%s'%tar]        ,'tmp_%s.root'%tar        ,'%s'%tar )\n",
    "to_root(df['%s_mix'%tar]    ,'tmp_%s_mix.root'%tar    ,'%s_mix'%tar )\n",
    "to_root(df['%s_trigger'%tar],'tmp_%s_trigger.root'%tar,'%s_trigger'%tar)\n",
    "#deuterium\n",
    "to_root(df['D_%s'%tar]        ,'tmp_D_%s.root'%tar        ,'D_%s'%tar )\n",
    "to_root(df['D_%s_mix'%tar]    ,'tmp_D_%s_mix.root'%tar    ,'D_%s_mix'%tar )\n",
    "to_root(df['D_%s_trigger'%tar],'tmp_D_%s_trigger.root'%tar,'D_%s_trigger'%tar)\n",
    "\n",
    "! hadd -f $outName tmp_*.root\n",
    "! rm tmp_*.root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outName='CC_Matching_Pairs'\n",
    "for target in ['Pb']:\n",
    "    to_root(df['%s'%target],'%s_%s.root'%(outName,target), key='%s'%target)\n",
    "    to_root(df['%s_mix'%target],'%s_%s.root'%(outName,target), key='%s_mix'%target,mode='a')\n",
    "    to_root(df['%s_trigger'%target],'%s_%s.root'%(outName,target), key='%s_trigger'%target, mode='a')\n",
    "    to_root(df['D_%s'%target],'%s_%s.root'%(outName,target), key='D_%s'%target,mode='a')\n",
    "    to_root(df['D_%s_mix'%target],'%s_%s.root'%(outName,target), key='D_%s_mix'%target,mode='a')\n",
    "    to_root(df['D_%s_trigger'%target],'%s_%s.root'%(outName,target), key='D_%s_trigger'%target, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with:  0  files\n",
      "/home/sebouh/di-hadron/simul/D/9.root\n",
      "/home/sebouh/di-hadron/simul/D/9.root  has  7840000  entries\n",
      "About to loop over  7840000  entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-b4a67b038703>:14: RuntimeWarning: invalid value encountered in arccos\n",
      "  self.PhiPQ = sign*np.arccos(part1.Dot(part2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed in 802.3305234909058 seconds\n",
      "Number of triggers with z>0.4,   671840\n",
      "Number of pairs with z>0.4,  600253\n",
      "Entries in the dataframe so far are  671840\n",
      "Entries in the MIXED dataframe so far are  429263\n",
      "Entries in the trigger dataframe so far are  600253\n",
      "done with:  1  files\n",
      "/home/sebouh/di-hadron/simul/D/1.root\n",
      "/home/sebouh/di-hadron/simul/D/1.root  has  8880000  entries\n",
      "About to loop over  8880000  entries\n",
      "Processed in 918.5672194957733 seconds\n",
      "Number of triggers with z>0.4,   760458\n",
      "Number of pairs with z>0.4,  677825\n",
      "Entries in the dataframe so far are  1432298\n",
      "Entries in the MIXED dataframe so far are  914756\n",
      "Entries in the trigger dataframe so far are  1278078\n",
      "done with:  2  files\n",
      "/home/sebouh/di-hadron/simul/D/2.root\n",
      "/home/sebouh/di-hadron/simul/D/2.root  has  8940000  entries\n",
      "About to loop over  8940000  entries\n",
      "Processed in 949.8190679550171 seconds\n",
      "Number of triggers with z>0.4,   764139\n",
      "Number of pairs with z>0.4,  681481\n",
      "Entries in the dataframe so far are  2196437\n",
      "Entries in the MIXED dataframe so far are  1402561\n",
      "Entries in the trigger dataframe so far are  1959559\n",
      "done with:  3  files\n",
      "/home/sebouh/di-hadron/simul/D/3.root\n",
      "/home/sebouh/di-hadron/simul/D/3.root  has  8460000  entries\n",
      "About to loop over  8460000  entries\n",
      "Processed in 871.8890500068665 seconds\n",
      "Number of triggers with z>0.4,   726297\n",
      "Number of pairs with z>0.4,  646190\n",
      "Entries in the dataframe so far are  2922734\n",
      "Entries in the MIXED dataframe so far are  1866751\n",
      "Entries in the trigger dataframe so far are  2605749\n",
      "done with:  4  files\n",
      "/home/sebouh/di-hadron/simul/D/5.root\n",
      "/home/sebouh/di-hadron/simul/D/5.root  has  8880000  entries\n",
      "About to loop over  8880000  entries\n",
      "Processed in 914.8397841453552 seconds\n",
      "Number of triggers with z>0.4,   758216\n",
      "Number of pairs with z>0.4,  676451\n",
      "Entries in the dataframe so far are  3680950\n",
      "Entries in the MIXED dataframe so far are  2351230\n",
      "Entries in the trigger dataframe so far are  3282200\n",
      "done with:  5  files\n",
      "/home/sebouh/di-hadron/simul/D/7.root\n",
      "/home/sebouh/di-hadron/simul/D/7.root  has  8740000  entries\n",
      "About to loop over  8740000  entries\n",
      "Processed in 902.6748778820038 seconds\n",
      "Number of triggers with z>0.4,   749792\n",
      "Number of pairs with z>0.4,  669274\n",
      "Entries in the dataframe so far are  4430742\n",
      "Entries in the MIXED dataframe so far are  2830873\n",
      "Entries in the trigger dataframe so far are  3951474\n",
      "done with:  6  files\n",
      "/home/sebouh/di-hadron/simul/D/6.root\n",
      "/home/sebouh/di-hadron/simul/D/6.root  has  8420000  entries\n",
      "About to loop over  8420000  entries\n",
      "Processed in 873.0355427265167 seconds\n",
      "Number of triggers with z>0.4,   725799\n",
      "Number of pairs with z>0.4,  646633\n",
      "Entries in the dataframe so far are  5156541\n",
      "Entries in the MIXED dataframe so far are  3293732\n",
      "Entries in the trigger dataframe so far are  4598107\n",
      "done with:  7  files\n",
      "/home/sebouh/di-hadron/simul/D/8.root\n",
      "/home/sebouh/di-hadron/simul/D/8.root  has  8640000  entries\n",
      "About to loop over  8640000  entries\n",
      "Processed in 897.7946882247925 seconds\n",
      "Number of triggers with z>0.4,   743042\n",
      "Number of pairs with z>0.4,  662707\n",
      "Entries in the dataframe so far are  5899583\n",
      "Entries in the MIXED dataframe so far are  3768174\n",
      "Entries in the trigger dataframe so far are  5260814\n",
      "done with:  8  files\n",
      "/home/sebouh/di-hadron/simul/D/4.root\n",
      "/home/sebouh/di-hadron/simul/D/4.root  has  8660000  entries\n",
      "About to loop over  8660000  entries\n",
      "Processed in 894.2259635925293 seconds\n",
      "Number of triggers with z>0.4,   740627\n",
      "Number of pairs with z>0.4,  660955\n",
      "Entries in the dataframe so far are  6640210\n",
      "Entries in the MIXED dataframe so far are  4241914\n",
      "Entries in the trigger dataframe so far are  5921769\n",
      "done with:  0  files\n",
      "/home/sebouh/di-hadron/simul/Fe/9.root\n",
      "/home/sebouh/di-hadron/simul/Fe/9.root  has  2723429  entries\n",
      "About to loop over  2723429  entries\n",
      "Processed in 273.853515625 seconds\n",
      "Number of triggers with z>0.4,   221548\n",
      "Number of pairs with z>0.4,  200414\n",
      "Entries in the dataframe so far are  221548\n",
      "Entries in the MIXED dataframe so far are  139253\n",
      "Entries in the trigger dataframe so far are  200414\n",
      "done with:  1  files\n",
      "/home/sebouh/di-hadron/simul/Fe/1.root\n",
      "/home/sebouh/di-hadron/simul/Fe/1.root  has  8980000  entries\n",
      "About to loop over  8980000  entries\n",
      "Processed in 895.7327778339386 seconds\n",
      "Number of triggers with z>0.4,   726920\n",
      "Number of pairs with z>0.4,  658136\n",
      "Entries in the dataframe so far are  948468\n",
      "Entries in the MIXED dataframe so far are  596276\n",
      "Entries in the trigger dataframe so far are  858550\n",
      "done with:  2  files\n",
      "/home/sebouh/di-hadron/simul/Fe/2.root\n",
      "/home/sebouh/di-hadron/simul/Fe/2.root  has  9400000  entries\n",
      "About to loop over  9400000  entries\n",
      "Processed in 943.7978329658508 seconds\n",
      "Number of triggers with z>0.4,   762962\n",
      "Number of pairs with z>0.4,  690159\n",
      "Entries in the dataframe so far are  1711430\n",
      "Entries in the MIXED dataframe so far are  1075910\n",
      "Entries in the trigger dataframe so far are  1548709\n",
      "done with:  3  files\n",
      "/home/sebouh/di-hadron/simul/Fe/3.root\n",
      "/home/sebouh/di-hadron/simul/Fe/3.root  has  5920000  entries\n",
      "About to loop over  5920000  entries\n",
      "Processed in 591.6816730499268 seconds\n",
      "Number of triggers with z>0.4,   478969\n",
      "Number of pairs with z>0.4,  432943\n",
      "Entries in the dataframe so far are  2190399\n",
      "Entries in the MIXED dataframe so far are  1377133\n",
      "Entries in the trigger dataframe so far are  1981652\n",
      "done with:  4  files\n",
      "/home/sebouh/di-hadron/simul/Fe/5.root\n",
      "/home/sebouh/di-hadron/simul/Fe/5.root  has  1400000  entries\n",
      "About to loop over  1400000  entries\n",
      "Processed in 140.3880317211151 seconds\n",
      "Number of triggers with z>0.4,   112834\n",
      "Number of pairs with z>0.4,  102608\n",
      "Entries in the dataframe so far are  2303233\n",
      "Entries in the MIXED dataframe so far are  1448781\n",
      "Entries in the trigger dataframe so far are  2084260\n",
      "done with:  5  files\n",
      "/home/sebouh/di-hadron/simul/Fe/7.root\n",
      "/home/sebouh/di-hadron/simul/Fe/7.root  has  1500000  entries\n",
      "About to loop over  1500000  entries\n",
      "Processed in 151.3765528202057 seconds\n",
      "Number of triggers with z>0.4,   122133\n",
      "Number of pairs with z>0.4,  110917\n",
      "Entries in the dataframe so far are  2425366\n",
      "Entries in the MIXED dataframe so far are  1525387\n",
      "Entries in the trigger dataframe so far are  2195177\n",
      "done with:  6  files\n",
      "/home/sebouh/di-hadron/simul/Fe/6.root\n",
      "/home/sebouh/di-hadron/simul/Fe/6.root  has  1420000  entries\n",
      "About to loop over  1420000  entries\n",
      "Processed in 142.92978405952454 seconds\n",
      "Number of triggers with z>0.4,   115937\n",
      "Number of pairs with z>0.4,  104578\n",
      "Entries in the dataframe so far are  2541303\n",
      "Entries in the MIXED dataframe so far are  1597709\n",
      "Entries in the trigger dataframe so far are  2299755\n",
      "done with:  7  files\n",
      "/home/sebouh/di-hadron/simul/Fe/8.root\n",
      "/home/sebouh/di-hadron/simul/Fe/8.root  has  760000  entries\n",
      "About to loop over  760000  entries\n",
      "Processed in 76.75031471252441 seconds\n",
      "Number of triggers with z>0.4,   62049\n",
      "Number of pairs with z>0.4,  55923\n",
      "Entries in the dataframe so far are  2603352\n",
      "Entries in the MIXED dataframe so far are  1636573\n",
      "Entries in the trigger dataframe so far are  2355678\n",
      "done with:  8  files\n",
      "/home/sebouh/di-hadron/simul/Fe/4.root\n",
      "/home/sebouh/di-hadron/simul/Fe/4.root  has  1780000  entries\n",
      "About to loop over  1780000  entries\n",
      "Processed in 178.66571044921875 seconds\n",
      "Number of triggers with z>0.4,   144029\n",
      "Number of pairs with z>0.4,  130495\n",
      "Entries in the dataframe so far are  2747381\n",
      "Entries in the MIXED dataframe so far are  1726849\n",
      "Entries in the trigger dataframe so far are  2486173\n",
      "done with:  0  files\n",
      "/home/sebouh/di-hadron/simul/Pb/9.root\n",
      "/home/sebouh/di-hadron/simul/Pb/9.root  has  2780000  entries\n",
      "About to loop over  2780000  entries\n",
      "Processed in 278.0516529083252 seconds\n",
      "Number of triggers with z>0.4,   223420\n",
      "Number of pairs with z>0.4,  203199\n",
      "Entries in the dataframe so far are  223420\n",
      "Entries in the MIXED dataframe so far are  141070\n",
      "Entries in the trigger dataframe so far are  203199\n",
      "done with:  1  files\n",
      "/home/sebouh/di-hadron/simul/Pb/1.root\n",
      "/home/sebouh/di-hadron/simul/Pb/1.root  has  1380000  entries\n",
      "About to loop over  1380000  entries\n",
      "Processed in 194.385404586792 seconds\n",
      "Number of triggers with z>0.4,   111870\n",
      "Number of pairs with z>0.4,  101061\n",
      "Entries in the dataframe so far are  335290\n",
      "Entries in the MIXED dataframe so far are  211620\n",
      "Entries in the trigger dataframe so far are  304260\n",
      "done with:  2  files\n",
      "/home/sebouh/di-hadron/simul/Pb/2.root\n",
      "/home/sebouh/di-hadron/simul/Pb/2.root  has  2220000  entries\n",
      "About to loop over  2220000  entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed in 222.45265126228333 seconds\n",
      "Number of triggers with z>0.4,   179699\n",
      "Number of pairs with z>0.4,  162987\n",
      "Entries in the dataframe so far are  514989\n",
      "Entries in the MIXED dataframe so far are  324880\n",
      "Entries in the trigger dataframe so far are  467247\n",
      "done with:  3  files\n",
      "/home/sebouh/di-hadron/simul/Pb/3.root\n",
      "/home/sebouh/di-hadron/simul/Pb/3.root  has  2200000  entries\n",
      "About to loop over  2200000  entries\n",
      "Processed in 220.952880859375 seconds\n",
      "Number of triggers with z>0.4,   178453\n",
      "Number of pairs with z>0.4,  161455\n",
      "Entries in the dataframe so far are  693442\n",
      "Entries in the MIXED dataframe so far are  437325\n",
      "Entries in the trigger dataframe so far are  628702\n",
      "done with:  4  files\n",
      "/home/sebouh/di-hadron/simul/Pb/5.root\n",
      "/home/sebouh/di-hadron/simul/Pb/5.root  has  1660000  entries\n",
      "About to loop over  1660000  entries\n",
      "Processed in 165.872376203537 seconds\n",
      "Number of triggers with z>0.4,   134354\n",
      "Number of pairs with z>0.4,  121894\n",
      "Entries in the dataframe so far are  827796\n",
      "Entries in the MIXED dataframe so far are  522242\n",
      "Entries in the trigger dataframe so far are  750596\n",
      "done with:  5  files\n",
      "/home/sebouh/di-hadron/simul/Pb/7.root\n",
      "/home/sebouh/di-hadron/simul/Pb/7.root  has  1580000  entries\n",
      "About to loop over  1580000  entries\n",
      "Processed in 159.2397608757019 seconds\n",
      "Number of triggers with z>0.4,   127243\n",
      "Number of pairs with z>0.4,  115504\n",
      "Entries in the dataframe so far are  955039\n",
      "Entries in the MIXED dataframe so far are  602090\n",
      "Entries in the trigger dataframe so far are  866100\n",
      "done with:  6  files\n",
      "/home/sebouh/di-hadron/simul/Pb/6.root\n",
      "/home/sebouh/di-hadron/simul/Pb/6.root  has  2020000  entries\n",
      "About to loop over  2020000  entries\n",
      "Processed in 202.79158449172974 seconds\n",
      "Number of triggers with z>0.4,   163086\n",
      "Number of pairs with z>0.4,  147871\n",
      "Entries in the dataframe so far are  1118125\n",
      "Entries in the MIXED dataframe so far are  705085\n",
      "Entries in the trigger dataframe so far are  1013971\n",
      "done with:  7  files\n",
      "/home/sebouh/di-hadron/simul/Pb/8.root\n",
      "/home/sebouh/di-hadron/simul/Pb/8.root  has  2340000  entries\n",
      "About to loop over  2340000  entries\n",
      "Processed in 236.4297890663147 seconds\n",
      "Number of triggers with z>0.4,   190483\n",
      "Number of pairs with z>0.4,  172765\n",
      "Entries in the dataframe so far are  1308608\n",
      "Entries in the MIXED dataframe so far are  825381\n",
      "Entries in the trigger dataframe so far are  1186736\n",
      "done with:  8  files\n",
      "/home/sebouh/di-hadron/simul/Pb/4.root\n",
      "/home/sebouh/di-hadron/simul/Pb/4.root  has  1940000  entries\n",
      "About to loop over  1940000  entries\n",
      "Processed in 195.71576404571533 seconds\n",
      "Number of triggers with z>0.4,   157126\n",
      "Number of pairs with z>0.4,  142207\n",
      "Entries in the dataframe so far are  1465734\n",
      "Entries in the MIXED dataframe so far are  924290\n",
      "Entries in the trigger dataframe so far are  1328943\n",
      "TFile: name=/home/sebouh/di-hadron/simul/D/9.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/D/1.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/D/2.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/D/3.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/D/5.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/D/7.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/D/6.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/D/8.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/D/4.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Fe/9.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Fe/1.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Fe/2.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Fe/3.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Fe/5.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Fe/7.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Fe/6.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Fe/8.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Fe/4.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Pb/9.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Pb/1.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Pb/2.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Pb/3.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Pb/5.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Pb/7.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Pb/6.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Pb/8.root, title=, option=READ\n",
      "TFile: name=/home/sebouh/di-hadron/simul/Pb/4.root, title=, option=READ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n",
      "Error in <TROOT::TVector2::Phi_mpi_pi>: function called with NaN\n"
     ]
    }
   ],
   "source": [
    "for a in 'D Fe Pb'.split():\n",
    "    dfs_mc={}\n",
    "    path = f'/home/sebouh/di-hadron/simul/{a}/'\n",
    "    #path = '/home/seba/di-hadron/simul/'\n",
    "    Files = listdir(path) \n",
    "    df_mc[a],df_mc[f'{a}_mix'], df_mc[f'{a}_trigger'] = [None,None,None]\n",
    "    count =0\n",
    "    for name in Files:\n",
    "        print('done with: ', count, ' files')\n",
    "        count=count+1\n",
    "        if( '.root' not in name): continue\n",
    "\n",
    "        filename = path+name\n",
    "        print(filename)\n",
    "        pairs, pairs_mix, trigger = getDataframes(filename,tree_name='ntuple_sim',Target=1,\n",
    "                                                  isMC=True,keepH2FailRecon=True)\n",
    "        df_mc[f'{a}'] = pd.concat([ df_mc[f'{a}'], pairs])\n",
    "        df_mc[f'{a}_mix'] = pd.concat([ df_mc[f'{a}_mix'], pairs_mix])\n",
    "        df_mc[f'{a}_trigger'] = pd.concat([ df_mc[f'{a}_trigger'], trigger])\n",
    "\n",
    "        print('Entries in the dataframe so far are ', df_mc[a].shape[0])\n",
    "        print('Entries in the MIXED dataframe so far are ', df_mc[f'{a}_mix'].shape[0])\n",
    "        print('Entries in the trigger dataframe so far are ', df_mc[f'{a}_trigger'].shape[0])\n",
    "    \n",
    "    root_pandas.to_root(df_mc[a],'MC_Pairs_%s_no_h2_kin_cuts.root'%a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_pandas.to_root_multi('MC_Pairs_%s_no_h2_kin_cuts.root'%a, df_mc)\n",
    "root_pandas.to_root(df_mc[a],'MC_Pairs_%s_no_h2_kin_cuts.root'%a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_mc['D'].hist(\"pass_recon\",bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module root_pandas:\n",
      "\n",
      "NAME\n",
      "    root_pandas\n",
      "\n",
      "FUNCTIONS\n",
      "    read_root(filename, treename=None, N=None)\n",
      "    \n",
      "    to_root(df, filename, treename)\n",
      "        #create single-tree root file\n",
      "    \n",
      "    to_root_multi(filename, d)\n",
      "        #create root file with multiple trees:\n",
      "        # d is a map of tree name to data frames {\"tree1\":df1, \"tree2\":df2 ... etc}\n",
      "\n",
      "FILE\n",
      "    /home/sebouh/di-hadron/root_pandas.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(root_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the MC file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in ['Pb']:\n",
    "    to_root(df_mc['%s'%target],'MC_Pairs_%s.root'%target, key='%s'%target)\n",
    "    to_root(df_mc['%s_mix'%target],'MC_Pairs_%s.root'%target, key='%s_mix'%target,mode='a')\n",
    "    to_root(df_mc['%s_trigger'%target],'MC_Pairs_%s.root'%target, key='%s_trigger'%target, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk in range(5):\n",
    "    print('inside the loop',kk)\n",
    "print('outside the loop',kk)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for ievt  in range(mytree.GetEntries()):\n",
    "        mytree.GetEntry(ievt)   \n",
    "        particles = []  ## this is how you define a list in python, this is created for each event\n",
    "        for i in range(len(mytree.pid)):\n",
    "            i_part = particle(mytree.pid[i], i_lv, virtual_photon, mytree.ThetaPQ[i], mytree.Nphe[i], mytree.deltaZ[i], mytree.FidCheckCutPiPlus[i])     \n",
    "            particles.append(i_part)\n",
    "            if i_part.Zh > 0.4: #only save triggers and do correlations if they have z>0.4\n",
    "                #tupla_trigger['h1_th'].append(mytree.ThetaLab[i])#i_part.LorentzVector.Theta())\n",
    "                #for j in range(len(mytree.pid)): \n",
    "                #    if i==j: continue\n",
    "                #    tupla['dphi'].append(dphi)\n",
    "                #print(ievt,i,j)\n",
    "                for mixparticle in ParticlesFromPrevious:\n",
    "                    print('inside mixparticle loop')\n",
    "                    #print(i,mixparticle, ParticlesFromPrevious)\n",
    "                    dphi = abs(ROOT.TVector2.Phi_mpi_pi(i_part.PhiPQ-mixparticle.PhiPQ))\n",
    "                    tupla_mix['dphi_norot'].append(dphi)\n",
    "\n",
    "                    mixparticle.redefine(virtual_photon) #recalculates variables in this' event photon frame (not in the previous one)\n",
    "                    tupla_mix['h2_th'].append(mytree.ThetaLab[j])\n",
    "        #print (' Exiting main loop over particles (i loop, not over all entries)')\n",
    "        ParticlesFromPrevious = particles\n",
    "        #print ' going for next event'    \n",
    "        #print ' particles in event', len(particles\n",
    "        ##end loop over events correlations    \n",
    "    end = time.time()\n",
    "    return df, df_mix, df_trigger        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
